{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FFk0grV-cDLo",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# import vowpal wabbit's python wrapper\n",
    "from vowpalwabbit import pyvw\n",
    "# cwd = os.getcwd()\n",
    "# cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jing: load data\n",
    "#data_path = '../ml-100k/'\n",
    "data_path = '../codes/'\n",
    "train_df = pd.read_csv(data_path + 'user_item_feature_100k.csv', sep=',', header = None)\n",
    "test_df = pd.read_csv(data_path + 'user_item_feature_100k_test.csv', sep=',', header = None)\n",
    "\n",
    "# test_df = 'user_item_feature_100k_test.csv'\n",
    "# test_df.rename(columns = {\"action\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment drop the userId itemId\n",
    "# train_df = train_df.drop([0,1], axis = 1) \n",
    "\n",
    "# test_df = test_df.drop([0,1], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train label distrubt', {1: 0.0589875, 2: 0.114725, 3: 0.2745375, 4: 0.34245, 5: 0.2093})\n",
      "('test label distrubt', {1: 0.06955, 2: 0.1096, 3: 0.2591, 4: 0.3389, 5: 0.22285})\n"
     ]
    }
   ],
   "source": [
    "label_ind = 29\n",
    "s = pd.Series(train_df[label_ind])\n",
    "label_count = s.value_counts(normalize=True).to_dict()\n",
    "print(\"train label distrubt\" , label_count)\n",
    "\n",
    "s = pd.Series(test_df[label_ind])\n",
    "label_count = s.value_counts(normalize=True).to_dict()\n",
    "print(\"test label distrubt\" , label_count)\n",
    "\n",
    "# hist, bin_edges = np.histogram(labs, density=True)\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-193753be380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training time with online 0.284865856171  seconds ---\n"
     ]
    }
   ],
   "source": [
    "# del vw\n",
    "# vw = pyvw.vw(\"--cb 2 --cb_type dm\") \n",
    "# vw = pyvw.vw(\"--cb_explore 2\")\n",
    "# vw = pyvw.vw(\"--cb 2 --cover 3\")\n",
    "# vw = pyvw.vw(\"--cb 2 --bag 5\")\n",
    "# vw = pyvw.vw(\"--cb 2 --epsilon 0.2\")\n",
    "# vw = pyvw.vw(\"--cb 2 --first 2\")\n",
    "# vw = pyvw.vw(\"--cb 2 --loss_function logistic --link logistic\")\n",
    "# 3 policies inverse propensity score (ips), direct method (dm), and doubly robust (dr, default).\n",
    "# vw = pyvw.vw(\"--cb 2 --holdout_after=20000\")\n",
    "\n",
    "# vw = pyvw.vw(\"--cb 2 --l1 1e-8 --passes 1\")#83.62\n",
    "vw = pyvw.vw(\"--cb 2 --quiet\")#83.64\n",
    "fea_ind_start = 0\n",
    "fea_ind_end = 29\n",
    "start_time = time.time()\n",
    "for i in range(400):#len(train_df)):\n",
    "    ## provide data to cb in requested format\n",
    "    seperator = \" \"\n",
    "    ins = train_df.iloc[i, fea_ind_start : fea_ind_end].tolist()\n",
    "    feature = seperator.join(str(e) for e in ins)\n",
    "    \n",
    "    if(train_df.loc[i,fea_ind_end] > 2 ):\n",
    "        action = 2         #train_df.loc[i, fea_ind_end]\n",
    "        probability = 0.5  #0.82085\n",
    "    else:\n",
    "        action = 1\n",
    "        probability = 0.5  #0.17915\n",
    "        \n",
    "    #if i%1000 == 0:\n",
    "    #    print(vw.get_loss())\n",
    "    choice = vw.predict(\"| \" + feature)\n",
    "    \n",
    "    if (action == choice):\n",
    "        cost = 0\n",
    "    else:\n",
    "        #print(action, choice)\n",
    "        cost = 1 \n",
    "        vw.learn(str(action)+\":\"+str(cost)+\":\"+str(probability)+\" | \" + feature)\n",
    "   \n",
    "    vw.learn(str(choice)+\":\"+str(cost)+\":\"+str(probability)+\" | \" + feature)\n",
    "print(\"--- training time with online %s  seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "vw.finish()\n",
    "# use the same model object that was trained to perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7154606464342847e-158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw.get_sum_loss()/len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict row by row and output results\n",
    "j = 1\n",
    "accu = 0\n",
    "start_time = time.time()\n",
    "num_samp = len(test_df)\n",
    "for j in range(100): #len(test_df)):\n",
    "    seperator = \" \"\n",
    "    ins = test_df.iloc[j, fea_ind_start : fea_ind_end].tolist()\n",
    "    feature = seperator.join(str(e) for e in ins)  \n",
    "    print(feature)\n",
    "    \n",
    "    \n",
    "    choice = vw.predict(\"| \" + feature)\n",
    "    \n",
    "    \n",
    "    pred_label  = choice\n",
    "    \n",
    "    # uncomment the following for explore    \n",
    "    #pred_label = choice.index(max(choice)) + 1\n",
    "    \n",
    "    if test_df.iloc[j, fea_ind_end] > 2:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 1\n",
    "    if label == pred_label:\n",
    "        accu = accu + 1\n",
    "    #else:\n",
    "    #print(pred_label, label, test_df.iloc[j,fea_ind_end])\n",
    "    \n",
    "print(\"--- testing time %s  seconds ---\" % (time.time() - start_time))\n",
    "print(accu,np.true_divide(accu, num_samp))\n",
    "# the CB assigns every instance to action 3 as it should per the cost structure of the train data; you can play with the cost structure to see that the CB updates its predictions accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83645"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accu,num_samp)\n",
    "np.true_divide(accu, num_samp)\n",
    "# 67.475 no warm start cost 1; prob 0.8:0.2; --cb 2; dr\n",
    "# 64.59 4000 warm start cost 1 prob 0.8:0.2; --cb 2; dr\n",
    "# 41.71  40000 warm start cost 1 prob 0.8:0.2; --cb 2; dr\n",
    "# 17.915  no warm start no test cost 0 prob 0.8:0.2; --cb 2; dr\n",
    "# 49.185  no warm start cost action - cost; train 150 seconds test 16seconds prob 0.8:0.2; --cb 2; dr\n",
    "# 66.615  no warm start cost cost - action; prob 0.8:0.2; --cb 2; dr\n",
    "# 83.645  no warm start cost 1; prob 0.5:0.5; --cb 2; dr\n",
    "# 17.915  no warm start no test cost 1; prob 0.5:05; --cb 2; dr\n",
    "# 82.615  no warm start cost 1; prob 0.2:0.8; --cb 2; dr\n",
    "# 45.815  no warm start cost 1; prob 0.9:0.1; --cb 2; dr\n",
    "# 83.39   no warm start cost 1; prob 0.5:0.5; --cb 2; dm \n",
    "# 60.3    no warm start cost 1; prob 0.5:0.5; --cb 2; ips\n",
    "# 60.45   no warm start cost 1; prob 0.5:0.5; --cb_explore 2; dr\n",
    "# 83.645   cover 3\n",
    "#  83.645        bag 5\n",
    "# 83.645   epsilon 0.1\n",
    "# 83.645   epsilon 0.5\n",
    "# 83.645 first 2000"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Implementing a Contextual Bandit Using VW's Python Wrapper.ipynb",
   "provenance": [
    {
     "file_id": "1Njy1txYPXqVwueHudbkF40zTbwkui1xA",
     "timestamp": 1519781379506
    },
    {
     "file_id": "11qz1CSi8-8yQACKJzp3G8VPUqzB3V1Hw",
     "timestamp": 1519780916480
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
